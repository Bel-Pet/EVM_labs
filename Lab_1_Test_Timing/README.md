# TestTiming

1. МЕТОДИКА ИЗМЕРЕНИЯ ВРЕМЕНИ ВЫПОЛНЕНИЯ
ПРИКЛАДНОЙ ПРОГРАММЫ
Измерение времени выполнения прикладной программы или ее частей
является одним из основных способов контроля характеристик аппаратного и
программного обеспечения с точки зрения быстродействия. Такой контроль,
с одной стороны, полезен для определения «узких мест» в алгоритме или
программе, которые нуждаются в оптимизации. С другой стороны, позволяет
судить о реальной производительности компьютера. Известно, что на время
выполнения программы влияют разные факторы:
 характеристики самой программы,
 архитектура и конфигурация компьютера,
 операционная система,
 совместно работающие процессы,
 состояние компьютера на момент старта программы,
 влияние измерителя времени и т.п.
Отделить влияние интересующих характеристик от прочих далеко не
всегда просто. Для этого существуют приемы, позволяющие снизить влияние
нежелательных факторов, а также интерпретировать полученные временные
характеристики запусков программ.
Время выполнения программы или её частей (далее – программы), как
правило, определяется разницей показаний таймера, которые снимаются
перед началом исполнения программы и после её завершения.
Независимо от используемого таймера, измерение времени работы
программы всегда выполняется с некоторой погрешностью (абсолютной или
относительной). Погрешность измерения используемого таймера не должна
выходить за рамки допустимой точности измерения. Величина допустимого
значения погрешности определяет тип таймера, которым следует
пользоваться при определении времени работы программы.
Абсолютная погрешность определяется разницей, например, в
секундах между временем таймера и точным временем выполнения
программы. Поскольку точное время выполнения программы никогда не
известно, то абсолютная погрешность измерения оценивается точностью
измерительного прибора. Например, если точность таймера 1 мс, то время
было измерено с погрешностью не более 1 мс.
Относительная погрешность – это отношение абсолютной погрешности
к величине временного интервала. Например, абсолютная погрешность в 1 мс
даст относительную погрешность в 50%, если весь интервал был 2 мс и 0,1%,
если интервал был 1 с. Таким образом, относительная погрешность
показывает величину погрешности относительно всего интервала времени.
В современном компьютере имеется несколько таймеров с разной
точностью. Для измерения времени работы программы можно использовать
и внешние измерительные приборы, например, секундомер. Если точность
выбранного таймера заведомо выше, чем требуется для заданного измерения,
это ещё не гарантирует, что полученный результат измерения выполнен с
требуемой точностью, т.к., возможно, измерение было искажено влиянием
посторонних факторов. Для уменьшения этого возможного влияния
существует ряд приёмов. Ниже приведена процедура измерения времени
выполнения программы.
Процедура измерения времени выполнения программы
1. Пусть задана величина допустимого значения погрешности и её тип
(относительная и/или абсолютная точность). Если требуется
удовлетворить только абсолютной точности измерения, то п.2. данной
процедуры пропускается.
2. Относительная точность преобразуется в абсолютную. Для этого
необходимо любым способом оценить время выполнения программы.
Далее выполняется п.3.
3. На компьютере, где будет выполняться измерение времени, оценивается
степень загрузки процессора другими процессами. Если степень загрузки
процессора высока, то выбирается таймер времени процесса, в противном
случае выбирается произвольный таймер, например, из списка таймеров в
п. «Способы получения показаний некоторых таймеров». Выбранный
таймер должен обеспечивать требуемую точность измерения времени,
иначе см. п.4.
4. Если доступные таймеры не могут обеспечить необходимую точность
измерения из-за малой величины измеряемого интервала времени,
увеличение точности измерения можно достигнуть следующим образом.
Программа многократно запускается в цикле, и измеряется общее время
выполнения этого цикла. Полученное значение времени выполнения
цикла делится на число итераций в цикле. Абсолютная погрешность
измерения уменьшится пропорционально числу итераций цикла.
5. Измеряется время выполнения программы с использованием приемов из
пункта «Приемы уменьшения влияния посторонних факторов на время
выполнения прикладной программы», затем проверяется качество
измерения в п.6.
6. Если по условию измерения времени программы требовалось обеспечить
абсолютную точность, то полученное время является результатом
измерения, в противном случае полученное измерение времени считается
новым оценочным временем выполнения программы, для которого ещё
раз вычисляется требуемая абсолютная точность из заданной
относительной. Если новая абсолютная точность выше, чем точность
выбранного таймера, то выполняется возврат к п.3 с новым оценочным
временем выполнения программы.
2. ПРИЕМЫ УМЕНЬШЕНИЯ ВЛИЯНИЯ ПОСТОРОННИХ
ФАКТОРОВ НА ВРЕМЯ ВЫПОЛНЕНИЯ ПРИКЛАДНОЙ
ПРОГРАММЫ
Многократное измерение. Время работы программы измеряется
несколько раз. Измерения, как правило, будут отличаться. Это связано с тем,
что сторонние факторы вносят различный вклад в измеряемый интервал при
каждом запуске. Время же работы самой программы остаётся неизменным.
Поэтому, из всех полученных измерений наиболее точным будет
минимальное.
Исключение из измерения стадий инициализации и завершения.
Если требуется измерить время работы некоторого фрагмента кода,
например, некоторой процедуры, то целесообразно вынести весь код
программы, предшествующий вызову процедуры, за первое измерение
времени работы программы, а второе измерение осуществлять сразу после
завершения её работы. Особенно это касается команд работы с устройствами
ввода-вывода (чтение с клавиатуры, вывод на экран, работа с файлами) и, в
меньшей степени, команд работы с оперативной памятью.
Уменьшение влияния кода измерения времени. Сам код снятия
показаний того или иного таймера выполняется не мгновенно. Это означает,
что в измеряемый интервал времени частично попадает и время его
исполнения. Это влияние следует, по возможности, уменьшать. Во-первых,
не следует снимать показания времени часто, особенно в циклах. В идеале,
код замера времени должен быть вызван лишь дважды – в начале и в конце
работы измеряемого фрагмента кода. Во-вторых, необходимо следить за тем,
чтобы измеряемый интервал был существенно больше, чем время работы
функции замера времени.
Уменьшение влияния посторонних процессов. В случаях, когда
процессор загружен другими процессами (например, системными
процессами или задачами других пользователей), для получения более
точного результата целесообразно использовать таймер времени выполнения
процесса (см. примеры соответствующих таймеров в разделе 5.3). Такие
таймеры, как правило, обладают более низкой точностью и плохо подходят
для измерения небольших интервалов времени.
Сброс буфера отложенной записи на диск. В современных
операционных системах, как правило, используется механизм кэширования
при работе с внешней памятью, например, жесткими дисками. Этот механизм
заключается в том, что при записи данных на диск данные сначала попадают
в буфер отложенной записи, который располагается в оперативной памяти, а
затем уже будут записаны позже. Этот механизм служит для ускорения
доступа к файлам и уменьшению износа аппаратного обеспечения. В таких
ОС возможна ситуация, когда во время работы вашей программы ОС решит
сгрузить накопленные данные на диск, что наверняка повлияет на чистоту
эксперимента. Поэтому перед проведением замеров времени следует
освобождать буфер отложенной записи на диск. В ОС Linux/UNIX это
делается с помощью утилиты sync. Эту команду можно набрать перед
запуском своей программы из командной строки, либо вызвать её прямо из
кода своей программы с помощью системного вызова system (см. system
(3) man page).

3. ТАЙМЕРЫ
Вычислительная система имеет несколько программных и аппаратных
таймеров, отражающих течение времени с различных точек зрения.
Необходимо различать следующие таймеры:
 Таймер системного времени (system time, wall-clock time) – аппаратный
счетчик, который отражает течение времени с точки зрения
вычислительной системы и, как правило, соответствует реальному
течению времени. Значение системного времени в каждый момент
одинаково для всех программ, работающих на данном компьютере.
Величина временного интервала, измеренного с помощью таймера
системного времени, включает в себя время работы не только
замеряющего процесса, но и других. Функции для получения
системного времени:
o Windows: GetSystemTime(), GetTickCount(), time(),
o Linux: gettimeofday(), times(), time(), clock_gettime().
Кроме того, в Windows используется функция clock(), которая
позволяет получить величину системного времени, прошедшего с
момента запуска данного процесса.
 Таймер времени процесса (process time, CPU time) – программный
счетчик, который отражает использование процессорного времени
только конкретным процессом. Шаг изменения этого счетчика
относительно велик, поэтому его не следует использовать для
измерения малых промежутков времени. Функции для получения
времени процесса:
o Windows: GetThreadTimes(),GetProcessTimes(),
o Linux: times(), clock().
 Счетчик тактов процессора (CPU time stamp counter) – аппаратный
счетчик, значение которого увеличивается на каждом такте процессора.
Такт процессора – самый малый интервал времени в вычислительной
системе, который теоретически может быть замерен. Поэтому счетчик
тактов позволяет с большой точностью измерять малые промежутки
времени (вплоть до нескольких команд процессора). Счетчик тактов
процессора имеет смысл использовать только для измерения
интервалов времени меньших кванта времени, выделяемого процессу
операционной системой. Для получения значения счетчика тактов
используются специальные команды процессора, свои для каждой
архитектуры:
o x86/x86-64: rdtsc,
o Alpha: rpcc,
o Itanium: ar.itc,
o PowerPC: mftb, mftbu.
4. СПОСОБЫ ПОЛУЧЕНИЯ ПОКАЗАНИЙ НЕКОТОРЫХ ТАЙМЕРОВ
4.1 Утилита time
Утилита time измеряет время работы приложения во многих
конфигурациях ОС GNU Linux/UNIX
Утилита time выдаёт следующие временные характеристики работы
программы:
real – общее время работы программы согласно системному таймеру,
user – время, которое работал пользовательский процесс (кроме
времени работы других процессов) и
sys – время, затраченное на выполнение системных вызовов
программы.
Дополнительная информация: time (1) man page.
Точность: определяется точностью системного таймера и точностью
измерения времени работы процесса (см. описание соответствующих
таймеров ниже).
Достоинство: готовая утилита, не требуется вносить изменения в
программу.
Недостаток: измеряется только время работы всей программы, нет
возможности измерить время работы отдельных её частей.
4.2 Библиотечная функция clock_gettime
Библиотечная функция clock_gettime получает значения
системного таймера в ОС Linux/UNIX
Функция clock_gettime с параметром CLOCK_MONOTONIC_RAW
сохраняет значение системного таймера в структуру struct timespec.
Структура состоит из двух полей: tv_sec и tv_nsec (можно считать их
тип long int), задающих количество секунд и наносекунд (10−9 cек.),
прошедших с некоторого неспецифицированного момента времени в
прошлом. В приведённом примере сохраняется значение таймера перед
выполнением некоторого кода и после него. Разница показаний
преобразуется в секунды и выводится на экран. Кроме системного таймера,
функция позволяет получать значения и других таймеров, например, времени
процесса или потока. Подробнее об этом можно прочитать в документации к
этой функции. Реализация функции clock_gettime находится в
библиотеке rt, поэтому при компиляции программы необходимо добавить
ключ компиляции ‘-lrt’. Пример команды компиляции (в некоторых
системах требуется ключ ‘-lrt’ писать в конце команды):
user@host:~$ gcc prog.c –o prog -lrt
Дополнительная информация: clock_gettime (3) man page.
Точность: зависит от точности системного таймера. Обычно в ОС
Windows: 55 мс (55∙10−3 с), в ОС GNU Linux/UNIX: 1 нс (1∙10−9 с).
Достоинство: переносимость – вне зависимости от аппаратного
обеспечения функция доступна пользователю, т.к. реализуется ОС.
Недостатки: относительно низкая точность (обычно ниже, чем у
счётчика тактов, но выше, чем у функции times), и измеренный интервал
включает время работы других процессов, которые работали на процессоре в
измеряемый период.
4.3 Библиотечная функция times
Функция измерения времени работы процесса times позволяет
определить время работы данного процесса в многозадачной операционной
системе, где каждый процессор (или ядро) выполняет несколько процессов
(программ) в режиме разделения времени (рис.19). Этот показатель особенно
важен, когда процессор сильно загружен другими процессами. В этом случае
показания, например, системного таймера могут быть очень далеки от
действительного времени работы программы. Процессор переключается
между процессами с некоторой периодичностью. В обычных Linux/UNIX
системах это около 10 мс (10−2 с). Функция times (листинг 3) позволяет
определить, сколько таких квантов времени проработал наш процесс. Если
перевести количество этих квантов во время, то можно определить, какое
время работал процесс.
В целом, её использование аналогично функции clock_gettime,
отличие состоит в преобразовании единиц измерения из квантов времени в
секунды. Количество квантов в секунду позволяет узнать системный вызов
sysconf.
Дополнительная информация: times(2) man page, sysconf (3) man page.
Точность: зависит от кванта планировщика процессов, обычно 10 мс
(10−2 с).
Достоинство: Из измеряемого времени исключается время, которое
работали другие процессы, это обеспечивает более точное измерение
времени работы программы на сильно загруженных процессорах по
сравнению с другими способами.
Недостаток: относительно низкая точность, определяемая квантом
времени переключения процессов.
4.4 Машинная команда rdtsc
Машинная команда rdtsc (Read Time Stamp Counter) снимает
показания счётчика тактов в виде 64-разрядного беззнакового целого числа,
равного количеству тактов, прошедших с момента запуска процессора
(листинг 4). Время в секундах получается делением количества тактов на
тактовую частоту процессора. В этом примере используется ассемблерная
вставка команды процессора rdtsc, результат выполнения который
записывается в объединение (union) ticks (старшая и младшая части).
Разница показаний счётчика тактов преобразовывается в секунды в
зависимости от тактовой частоты. Узнать тактовую частоту процессора в ОС
Linux/UNIX 
Точность: один такт (величина в секундах зависит от тактовой частоты
процессора).
Достоинство: максимально возможная точность измерения времени.
Недостатки: привязка к архитектуре x86, в других архитектурах могут
существовать аналогичные машинные команды. Затруднительно
преобразование в секунды в процессорах с динамическим изменением
частоты.
5. ЗАДАНИЕ К ЛАБОРАТОРНОЙ РАБОТЕ
1. Написать программу на языке C или C++, которая реализует
выбранный алгоритм из задания.
Алгоритм вычисления функции ln(1+x) с помощью разложения в ряд по
первым N членам этого ряда.
2. Проверить правильность работы программы на нескольких тестовых
наборах входных данных.
3. Выбрать значение параметра N таким, чтобы время работы программы
было порядка 15 секунд.
4. По приведенной методике определить время работы подпрограммы
тестовой программы с относительной погрешностью не более 1%.
